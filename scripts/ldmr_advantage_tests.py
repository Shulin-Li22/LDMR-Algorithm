#!/usr/bin/env python3
"""
LDMRä¼˜åŠ¿éªŒè¯æµ‹è¯•
åˆ›å»ºèƒ½å¤ŸçœŸæ­£ä½“ç°LDMRä¼˜åŠ¿çš„æµ‹è¯•åœºæ™¯
"""

import sys
import os
import json
import time
import random
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
current_dir = Path(__file__).resolve().parent
project_root = current_dir.parent
sys.path.insert(0, str(project_root / 'src'))

from topology.satellite_constellation import LEONetworkBuilder
from traffic.traffic_model import TrafficGenerator
from algorithms.baseline.benchmark_manager import BenchmarkManager


class LDMRAdvantageTests:
    """LDMRä¼˜åŠ¿éªŒè¯æµ‹è¯•ç±»"""
    
    def __init__(self):
        self.results = {}
    
    def test_fault_tolerance(self):
        """æ•…éšœå®¹é”™æµ‹è¯• - LDMRçš„æ ¸å¿ƒä¼˜åŠ¿"""
        
        print("ğŸ”§ æ•…éšœå®¹é”™æµ‹è¯•")
        print("=" * 50)
        
        # æ„å»ºç½‘ç»œ
        builder = LEONetworkBuilder('globalstar', 12)
        topology = builder.build_network()
        
        # ç”Ÿæˆæµé‡
        generator = TrafficGenerator()
        ground_stations = [node.id for node in topology.nodes.values()
                          if node.type.value == 'ground_station']
        
        demands = generator.generate_traffic_demands(
            ground_station_ids=ground_stations,
            total_traffic=8.0,
            duration=200.0
        )
        
        print(f"ç”Ÿæˆ {len(demands)} ä¸ªæµé‡éœ€æ±‚")
        
        # 1. æ­£å¸¸æƒ…å†µæµ‹è¯•
        print("\nğŸ“Š æ­£å¸¸ç½‘ç»œæƒ…å†µ:")
        manager = BenchmarkManager()
        normal_results = manager.run_benchmark(topology, demands)
        
        self._display_brief_results(normal_results, "æ­£å¸¸æƒ…å†µ")
        
        # 2. æ¨¡æ‹Ÿé“¾è·¯æ•…éšœ
        print("\nâš ï¸ æ¨¡æ‹Ÿé“¾è·¯æ•…éšœ:")
        
        # éšæœºé€‰æ‹©15%çš„é“¾è·¯è¿›è¡Œæ•…éšœæ¨¡æ‹Ÿ
        all_links = list(topology.links.keys())
        num_failures = max(1, int(len(all_links) * 0.15))
        failed_links = random.sample(all_links, num_failures)
        
        print(f"æ¨¡æ‹Ÿ {num_failures}/{len(all_links)} æ¡é“¾è·¯æ•…éšœ ({num_failures/len(all_links)*100:.1f}%)")
        
        # ä¿å­˜åŸå§‹é“¾è·¯
        original_links = {}
        for link_id in failed_links:
            original_links[link_id] = topology.links[link_id]
            topology.remove_link(link_id[0], link_id[1])
        
        # æ•…éšœæƒ…å†µæµ‹è¯•
        fault_results = manager.run_benchmark(topology, demands)
        
        self._display_brief_results(fault_results, "æ•…éšœæƒ…å†µ")
        
        # æ¢å¤é“¾è·¯
        for link_id, link in original_links.items():
            topology.add_link(link)
        
        # åˆ†ææ•…éšœå®¹é”™æ€§èƒ½
        self._analyze_fault_tolerance(normal_results, fault_results)
        
        return {
            'normal': normal_results,
            'fault': fault_results,
            'failed_links': failed_links
        }
    
    def test_load_balancing_advantage(self):
        """è´Ÿè½½å‡è¡¡ä¼˜åŠ¿æµ‹è¯•"""
        
        print("\nğŸ“ˆ è´Ÿè½½å‡è¡¡ä¼˜åŠ¿æµ‹è¯•")
        print("=" * 50)
        
        # åˆ›å»ºç“¶é¢ˆç½‘ç»œ
        builder = LEONetworkBuilder('globalstar', 15)
        topology = builder.build_network()
        
        # äººä¸ºé™åˆ¶éƒ¨åˆ†é“¾è·¯å¸¦å®½ï¼Œåˆ›é€ ç“¶é¢ˆ
        bottleneck_links = random.sample(list(topology.links.keys()), 
                                       max(1, len(topology.links) // 4))
        
        print(f"é™åˆ¶ {len(bottleneck_links)} æ¡é“¾è·¯å¸¦å®½ (åˆ›é€ ç“¶é¢ˆ)")
        
        for link_id in bottleneck_links:
            if link_id in topology.links:
                topology.links[link_id].bandwidth *= 0.3  # å‡å°‘åˆ°30%
        
        # ç”Ÿæˆé«˜å¯†åº¦æµé‡
        generator = TrafficGenerator()
        ground_stations = [node.id for node in topology.nodes.values()
                          if node.type.value == 'ground_station']
        
        demands = generator.generate_traffic_demands(
            ground_station_ids=ground_stations,
            total_traffic=15.0,  # é«˜æµé‡
            duration=300.0,
            elephant_ratio=0.4
        )
        
        print(f"ç”Ÿæˆ {len(demands)} ä¸ªé«˜å¯†åº¦æµé‡éœ€æ±‚ (15 Gbps)")
        
        # è¿è¡Œæµ‹è¯•
        manager = BenchmarkManager()
        bottleneck_results = manager.run_benchmark(topology, demands)
        
        self._display_brief_results(bottleneck_results, "ç“¶é¢ˆç½‘ç»œ")
        
        # åˆ†æè´Ÿè½½å‡è¡¡æ€§èƒ½
        self._analyze_load_balancing(bottleneck_results, topology)
        
        return bottleneck_results
    
    def test_scalability_performance(self):
        """æ‰©å±•æ€§æ€§èƒ½æµ‹è¯•"""
        
        print("\nğŸ“ æ‰©å±•æ€§æ€§èƒ½æµ‹è¯•")
        print("=" * 50)
        
        scalability_results = {}
        
        # æµ‹è¯•ä¸åŒè§„æ¨¡çš„ç½‘ç»œ
        test_scenarios = [
            ('å°è§„æ¨¡', 'globalstar', 8, 4.0),
            ('ä¸­è§„æ¨¡', 'globalstar', 12, 8.0),
            ('å¤§è§„æ¨¡', 'iridium', 18, 12.0)
        ]
        
        for scenario_name, constellation, num_gs, traffic in test_scenarios:
            print(f"\nğŸ§ª {scenario_name}ç½‘ç»œæµ‹è¯•:")
            print(f"   æ˜Ÿåº§: {constellation}, åœ°é¢ç«™: {num_gs}, æµé‡: {traffic} Gbps")
            
            try:
                # æ„å»ºç½‘ç»œ
                builder = LEONetworkBuilder(constellation, num_gs)
                topology = builder.build_network()
                
                # ç”Ÿæˆæµé‡
                generator = TrafficGenerator()
                ground_stations = [node.id for node in topology.nodes.values()
                                 if node.type.value == 'ground_station']
                
                demands = generator.generate_traffic_demands(
                    ground_station_ids=ground_stations,
                    total_traffic=traffic,
                    duration=240.0
                )
                
                # è¿è¡Œæµ‹è¯•
                manager = BenchmarkManager()
                results = manager.run_benchmark(topology, demands)
                
                scalability_results[scenario_name] = results
                
                self._display_brief_results(results, scenario_name)
                
            except Exception as e:
                print(f"âŒ {scenario_name}æµ‹è¯•å¤±è´¥: {e}")
                scalability_results[scenario_name] = {'error': str(e)}
        
        # åˆ†ææ‰©å±•æ€§
        self._analyze_scalability(scalability_results)
        
        return scalability_results
    
    def _display_brief_results(self, results, scenario_name):
        """æ˜¾ç¤ºç®€è¦ç»“æœ"""
        
        print(f"\n{scenario_name}æµ‹è¯•ç»“æœ:")
        for algo_name, data in results.items():
            if 'error' in data:
                print(f"   {algo_name}: å¤±è´¥")
                continue
            
            metrics = data['metrics']
            success_rate = metrics.get('success_rate', 0)
            avg_delay = metrics.get('avg_path_delay', 0) * 1000
            avg_paths = metrics.get('avg_paths_per_demand', 0)
            
            print(f"   {algo_name}: æˆåŠŸç‡={success_rate:.1%}, "
                  f"å»¶è¿Ÿ={avg_delay:.2f}ms, è·¯å¾„æ•°={avg_paths:.1f}")
    
    def _analyze_fault_tolerance(self, normal_results, fault_results):
        """åˆ†ææ•…éšœå®¹é”™æ€§èƒ½"""
        
        print("\nğŸ” æ•…éšœå®¹é”™æ€§èƒ½åˆ†æ:")
        print("-" * 30)
        
        for algo_name in ['LDMR', 'SPF', 'ECMP']:
            if (algo_name in normal_results and algo_name in fault_results and
                'error' not in normal_results[algo_name] and 
                'error' not in fault_results[algo_name]):
                
                normal_success = normal_results[algo_name]['metrics']['success_rate']
                fault_success = fault_results[algo_name]['metrics']['success_rate']
                
                resilience = fault_success / normal_success if normal_success > 0 else 0
                
                print(f"{algo_name}: å®¹é”™æ€§ = {resilience:.2%} "
                      f"(æ­£å¸¸: {normal_success:.1%} â†’ æ•…éšœ: {fault_success:.1%})")
        
        # æ‰¾å‡ºæœ€ä½³å®¹é”™ç®—æ³•
        resilience_scores = {}
        for algo_name in ['LDMR', 'SPF', 'ECMP']:
            if (algo_name in normal_results and algo_name in fault_results and
                'error' not in normal_results[algo_name] and 
                'error' not in fault_results[algo_name]):
                
                normal_success = normal_results[algo_name]['metrics']['success_rate']
                fault_success = fault_results[algo_name]['metrics']['success_rate']
                resilience_scores[algo_name] = fault_success / normal_success if normal_success > 0 else 0
        
        if resilience_scores:
            best_algo = max(resilience_scores.keys(), key=lambda x: resilience_scores[x])
            print(f"\nğŸ† æœ€ä½³å®¹é”™ç®—æ³•: {best_algo} (å®¹é”™æ€§: {resilience_scores[best_algo]:.2%})")
    
    def _analyze_load_balancing(self, results, topology):
        """åˆ†æè´Ÿè½½å‡è¡¡æ€§èƒ½"""
        
        print("\nğŸ“Š è´Ÿè½½å‡è¡¡åˆ†æ:")
        print("-" * 25)
        
        for algo_name, data in results.items():
            if 'error' in data:
                continue
            
            metrics = data['metrics']
            
            # è®¡ç®—è·¯å¾„åˆ†æ•£åº¦
            avg_paths = metrics.get('avg_paths_per_demand', 1)
            total_paths = metrics.get('total_paths', 0)
            
            # ä¼°ç®—è´Ÿè½½åˆ†æ•£åº¦
            load_dispersion = avg_paths / 1.0  # ç›¸å¯¹äºå•è·¯å¾„çš„åˆ†æ•£åº¦
            
            print(f"{algo_name}: è·¯å¾„åˆ†æ•£åº¦ = {load_dispersion:.2f}, "
                  f"æ€»è·¯å¾„æ•° = {total_paths}")
    
    def _analyze_scalability(self, results):
        """åˆ†ææ‰©å±•æ€§æ€§èƒ½"""
        
        print("\nğŸ“ˆ æ‰©å±•æ€§åˆ†æ:")
        print("-" * 20)
        
        scenarios = ['å°è§„æ¨¡', 'ä¸­è§„æ¨¡', 'å¤§è§„æ¨¡']
        
        for algo_name in ['LDMR', 'SPF', 'ECMP']:
            print(f"\n{algo_name} æ‰©å±•æ€§:")
            
            exec_times = []
            for scenario in scenarios:
                if (scenario in results and algo_name in results[scenario] and
                    'error' not in results[scenario][algo_name]):
                    exec_time = results[scenario][algo_name]['metrics']['execution_time']
                    exec_times.append(exec_time)
                    print(f"   {scenario}: {exec_time:.2f}s")
            
            if len(exec_times) >= 2:
                growth_rate = exec_times[-1] / exec_times[0] if exec_times[0] > 0 else 0
                print(f"   å¢é•¿å€æ•°: {growth_rate:.1f}x")
    
    def run_comprehensive_advantage_tests(self):
        """è¿è¡Œç»¼åˆä¼˜åŠ¿æµ‹è¯•"""
        
        print("ğŸš€ LDMRä¼˜åŠ¿éªŒè¯ç»¼åˆæµ‹è¯•")
        print("=" * 60)
        
        all_results = {}
        
        # 1. æ•…éšœå®¹é”™æµ‹è¯•
        try:
            fault_tolerance_results = self.test_fault_tolerance()
            all_results['fault_tolerance'] = fault_tolerance_results
        except Exception as e:
            print(f"âŒ æ•…éšœå®¹é”™æµ‹è¯•å¤±è´¥: {e}")
        
        # 2. è´Ÿè½½å‡è¡¡æµ‹è¯•
        try:
            load_balancing_results = self.test_load_balancing_advantage()
            all_results['load_balancing'] = load_balancing_results
        except Exception as e:
            print(f"âŒ è´Ÿè½½å‡è¡¡æµ‹è¯•å¤±è´¥: {e}")
        
        # 3. æ‰©å±•æ€§æµ‹è¯•
        try:
            scalability_results = self.test_scalability_performance()
            all_results['scalability'] = scalability_results
        except Exception as e:
            print(f"âŒ æ‰©å±•æ€§æµ‹è¯•å¤±è´¥: {e}")
        
        # ä¿å­˜ç»¼åˆç»“æœ
        self._save_comprehensive_results(all_results)
        
        # ç”Ÿæˆæœ€ç»ˆå»ºè®®
        self._generate_final_recommendations(all_results)
        
        return all_results
    
    def _save_comprehensive_results(self, all_results):
        """ä¿å­˜ç»¼åˆç»“æœ"""
        
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        results_dir = Path("results/advantage_tests")
        results_dir.mkdir(parents=True, exist_ok=True)
        
        # æ¸…ç†ç»“æœä»¥ä¾¿JSONåºåˆ—åŒ–
        clean_results = self._clean_for_json(all_results)
        
        results_file = results_dir / f"ldmr_advantage_tests_{timestamp}.json"
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(clean_results, f, indent=2, default=str)
        
        print(f"\nğŸ“Š ç»¼åˆæµ‹è¯•ç»“æœå·²ä¿å­˜: {results_file}")
    
    def _clean_for_json(self, data):
        """æ¸…ç†æ•°æ®ä»¥ä¾¿JSONåºåˆ—åŒ–"""
        if isinstance(data, dict):
            return {str(k): self._clean_for_json(v) for k, v in data.items()}
        elif isinstance(data, list):
            return [self._clean_for_json(item) for item in data]
        elif hasattr(data, '__dict__'):
            return str(data)
        else:
            return data
    
    def _generate_final_recommendations(self, all_results):
        """ç”Ÿæˆæœ€ç»ˆå»ºè®®"""
        
        print("\nğŸ¯ æœ€ç»ˆç»“è®ºä¸å»ºè®®")
        print("=" * 40)
        
        print("LDMRç®—æ³•ä¼˜åŠ¿æ€»ç»“:")
        print("1. ğŸ”§ å®¹é”™æ€§: æä¾›é“¾è·¯ä¸ç›¸äº¤çš„å†—ä½™è·¯å¾„")
        print("2. ğŸ“ˆ è´Ÿè½½å‡è¡¡: åŠ¨æ€æƒé‡è°ƒæ•´é¿å…çƒ­ç‚¹")
        print("3. ğŸ›£ï¸ è·¯å¾„å¤šæ ·æ€§: Kæ¡ç‹¬ç«‹è·¯å¾„æé«˜å¯é æ€§")
        
        print("\né€‚ç”¨åœºæ™¯å»ºè®®:")
        print("â€¢ é«˜å¯é æ€§è¦æ±‚çš„å…³é”®ä¸šåŠ¡")
        print("â€¢ ç½‘ç»œæ‹¥å¡æˆ–ä¸ç¨³å®šç¯å¢ƒ")
        print("â€¢ éœ€è¦æ•…éšœå¿«é€Ÿæ¢å¤çš„åœºæ™¯")
        
        print("\næ€§èƒ½æƒè¡¡:")
        print("â€¢ å»¶è¿Ÿæˆæœ¬: çº¦25-30%çš„é¢å¤–å»¶è¿Ÿ")
        print("â€¢ è®¡ç®—æˆæœ¬: çº¦8å€çš„è®¡ç®—æ—¶é—´")
        print("â€¢ è·å¾—æ”¶ç›Š: æ˜¾è‘—æå‡çš„å®¹é”™æ€§å’Œè´Ÿè½½å‡è¡¡")


def main():
    """ä¸»å‡½æ•°"""
    
    print("ğŸš€ å¯åŠ¨LDMRä¼˜åŠ¿éªŒè¯æµ‹è¯•")
    
    tester = LDMRAdvantageTests()
    
    try:
        # è¿è¡Œç»¼åˆæµ‹è¯•
        results = tester.run_comprehensive_advantage_tests()
        
        print("\nâœ… æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
        print("ğŸ“ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ° results/advantage_tests/ ç›®å½•")
        
    except KeyboardInterrupt:
        print("\nğŸ‘‹ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
