"""
LDMR (Link Disjoint Multipath Routing) ç®—æ³•å®ç°
åŸºäºè®ºæ–‡ "A GNN-Enabled Multipath Routing Algorithm for Spatial-Temporal Varying LEO Satellite Networks"
Algorithm 1 çš„å®Œæ•´å®ç°
"""

import random
import numpy as np
import time
from typing import List, Dict, Tuple, Set, Optional
from dataclasses import dataclass
from enum import Enum

try:
    from topology.topology_base import NetworkTopology, Link
    from algorithms.basic_algorithms import DijkstraPathFinder, PathInfo
    from traffic.traffic_model import TrafficDemand
except ImportError:
    try:
        from ..topology.topology_base import NetworkTopology, Link
        from .basic_algorithms import DijkstraPathFinder, PathInfo
        from ..traffic.traffic_model import TrafficDemand
    except ImportError:
        from topology_base import NetworkTopology, Link
        from basic_algorithms import DijkstraPathFinder, PathInfo
        from traffic_model import TrafficDemand


@dataclass
class LDMRConfig:
    """LDMRç®—æ³•é…ç½®å‚æ•°"""
    K: int = 2  # æ¯ä¸ªèŠ‚ç‚¹å¯¹çš„è·¯å¾„æ•°é‡ (è®ºæ–‡ä¸­K=2ä¸ºæœ€ä¼˜)
    r1: int = 1  # æƒé‡ä¸‹ç•Œ1
    r2: int = 10  # æƒé‡ä¸‹ç•Œ2
    r3: int = 50  # æƒé‡ä¸Šç•Œ (è®ºæ–‡æµ‹è¯•ç»“æœæ˜¾ç¤º50ä¸ºæœ€ä¼˜å€¼)
    Ne_th: int = 2  # é“¾è·¯åˆ©ç”¨é¢‘æ¬¡é˜ˆå€¼
    max_iterations: int = 10  # æœ€å¤§è¿­ä»£æ¬¡æ•°
    enable_statistics: bool = True  # æ˜¯å¦å¯ç”¨è¯¦ç»†ç»Ÿè®¡


@dataclass
class MultiPathResult:
    """å¤šè·¯å¾„è®¡ç®—ç»“æœ"""
    source_id: str
    destination_id: str
    paths: List[PathInfo]
    demand: TrafficDemand
    success: bool = True
    computation_time: float = 0.0  # è®¡ç®—æ—¶é—´(ç§’)

    @property
    def total_delay(self) -> float:
        """æ‰€æœ‰è·¯å¾„çš„æ€»å»¶è¿Ÿ"""
        return sum(path.total_delay for path in self.paths)

    @property
    def min_delay(self) -> float:
        """æœ€å°è·¯å¾„å»¶è¿Ÿ"""
        return min(path.total_delay for path in self.paths) if self.paths else float('inf')

    @property
    def total_hops(self) -> int:
        """æ‰€æœ‰è·¯å¾„çš„æ€»è·³æ•°"""
        return sum(path.length for path in self.paths)

    def __str__(self):
        return f"MultiPath({self.source_id}->{self.destination_id}, {len(self.paths)} paths, {self.success})"


class LDMRAlgorithm:
    """LDMRç®—æ³•ä¸»ç±» - å®ç°è®ºæ–‡Algorithm 1"""

    def __init__(self, config: LDMRConfig = None):
        self.config = config or LDMRConfig()
        self.link_usage_count: Dict[Tuple[str, str], int] = {}
        self.calculated_paths: Dict[Tuple[str, str], List[PathInfo]] = {}
        self.execution_stats = {
            'total_time': 0.0,
            'path_calculations': 0,
            'weight_updates': 0,
            'link_removals': 0
        }

    def reset_algorithm_state(self):
        """é‡ç½®ç®—æ³•çŠ¶æ€ (Algorithm 1, Steps 1-5)"""
        self.link_usage_count.clear()
        self.calculated_paths.clear()
        if self.config.enable_statistics:
            self.execution_stats = {
                'total_time': 0.0,
                'path_calculations': 0,
                'weight_updates': 0,
                'link_removals': 0
            }

    def increment_link_usage(self, path: PathInfo):
        """å¢åŠ è·¯å¾„ä¸Šæ‰€æœ‰é“¾è·¯çš„ä½¿ç”¨è®¡æ•° (Algorithm 1, Step 10)"""
        for link_tuple in path.links:
            link_id = tuple(sorted(link_tuple))
            self.link_usage_count[link_id] = self.link_usage_count.get(link_id, 0) + 1

            if self.config.enable_statistics:
                self.execution_stats['path_calculations'] += 1

    def get_link_usage_count(self, node1: str, node2: str) -> int:
        """è·å–é“¾è·¯çš„ä½¿ç”¨è®¡æ•°"""
        link_id = tuple(sorted([node1, node2]))
        return self.link_usage_count.get(link_id, 0)

    def update_weight_matrix(self, topology: NetworkTopology, excluded_links: Set[Tuple[str, str]] = None):
        """
        æ›´æ–°æƒé‡çŸ©é˜µ (Algorithm 1, Steps 13-19)

        æ ¹æ®é“¾è·¯ä½¿ç”¨é¢‘æ¬¡åŠ¨æ€è°ƒæ•´æƒé‡:
        - ä½¿ç”¨é¢‘æ¬¡ < Ne_th: æƒé‡èŒƒå›´ [r1, r2] (è¾ƒå°æƒé‡ï¼Œé¼“åŠ±ä½¿ç”¨)
        - ä½¿ç”¨é¢‘æ¬¡ >= Ne_th: æƒé‡èŒƒå›´ [r2, r3] (è¾ƒå¤§æƒé‡ï¼Œé¿å…è¿‡åº¦ä½¿ç”¨)
        """
        excluded_links = excluded_links or set()
        weight_updates = {}

        for link_id, link in topology.links.items():
            # è·³è¿‡æ’é™¤çš„é“¾è·¯
            if link_id in excluded_links:
                continue

            usage_count = self.get_link_usage_count(link.node1_id, link.node2_id)

            # Algorithm 1, Steps 14-18: æ ¹æ®ä½¿ç”¨é¢‘æ¬¡æ›´æ–°æƒé‡
            if usage_count < self.config.Ne_th:
                # ä½¿ç”¨é¢‘æ¬¡è¾ƒä½ï¼Œåˆ†é…è¾ƒå°æƒé‡ (r1, r2)
                new_weight = random.randint(self.config.r1, self.config.r2)
            else:
                # ä½¿ç”¨é¢‘æ¬¡è¾ƒé«˜ï¼Œåˆ†é…è¾ƒå¤§æƒé‡ (r2, r3)
                new_weight = random.randint(self.config.r2, self.config.r3)

            weight_updates[link_id] = new_weight

        # æ‰¹é‡æ›´æ–°æƒé‡
        topology.update_link_weights(weight_updates)

        if self.config.enable_statistics:
            self.execution_stats['weight_updates'] += len(weight_updates)

    def calculate_shortest_delay_paths(self, topology: NetworkTopology,
                                       traffic_demands: List[TrafficDemand]) -> Dict[Tuple[str, str], PathInfo]:
        """
        è®¡ç®—æ‰€æœ‰èŠ‚ç‚¹å¯¹çš„æœ€çŸ­å»¶è¿Ÿè·¯å¾„ (Algorithm 1, Steps 6-10)

        ä½¿ç”¨Dijkstraç®—æ³•åŸºäºé“¾è·¯å»¶è¿Ÿè®¡ç®—æœ€çŸ­è·¯å¾„ï¼Œä¸ºåç»­å¤šè·¯å¾„è®¡ç®—æä¾›ç¬¬ä¸€æ¡è·¯å¾„
        """
        shortest_paths = {}
        path_finder = DijkstraPathFinder(topology)

        # æå–æ‰€æœ‰å”¯ä¸€çš„æº-ç›®çš„èŠ‚ç‚¹å¯¹
        node_pairs = set((demand.source_id, demand.destination_id) for demand in traffic_demands)

        print(f"     è®¡ç®— {len(node_pairs)} ä¸ªèŠ‚ç‚¹å¯¹çš„æœ€çŸ­å»¶è¿Ÿè·¯å¾„...")

        for source, destination in node_pairs:
            path = path_finder.find_shortest_path(source, destination, weight_type='delay')
            if path:
                shortest_paths[(source, destination)] = path
                # æ›´æ–°é“¾è·¯ä½¿ç”¨è®¡æ•° (Algorithm 1, Step 10)
                self.increment_link_usage(path)

        return shortest_paths

    def find_backup_path_with_excluded_links(self, topology: NetworkTopology,
                                             source: str, destination: str,
                                             excluded_links: Set[Tuple[str, str]]) -> Optional[PathInfo]:
        """
        æŸ¥æ‰¾å¤‡ç”¨è·¯å¾„ï¼Œæ’é™¤æŒ‡å®šé“¾è·¯ (Algorithm 1, Steps 23-28)

        åˆ›å»ºä¸´æ—¶æ‹“æ‰‘ç§»é™¤å·²ä½¿ç”¨çš„é“¾è·¯ï¼Œç„¶ååœ¨æ›´æ–°æƒé‡åè®¡ç®—è·¯å¾„
        """
        # åˆ›å»ºæ‹“æ‰‘å‰¯æœ¬
        temp_topology = topology.copy()

        # ç§»é™¤æ’é™¤çš„é“¾è·¯ (Algorithm 1, Step 24)
        for link_id in excluded_links:
            if len(link_id) == 2:
                temp_topology.remove_link(link_id[0], link_id[1])
                if self.config.enable_statistics:
                    self.execution_stats['link_removals'] += 1

        # æ›´æ–°æƒé‡çŸ©é˜µ (Algorithm 1, Steps 25-26)
        self.update_weight_matrix(temp_topology)

        # åœ¨æ›´æ–°åçš„æ‹“æ‰‘ä¸ŠæŸ¥æ‰¾è·¯å¾„ (Algorithm 1, Step 27)
        path_finder = DijkstraPathFinder(temp_topology)
        backup_path = path_finder.find_shortest_path(source, destination, weight_type='weight')

        return backup_path

    def calculate_multipath_for_single_demand(self, topology: NetworkTopology,
                                              demand: TrafficDemand,
                                              existing_shortest_paths: Dict[
                                                  Tuple[str, str], PathInfo]) -> MultiPathResult:
        """
        ä¸ºå•ä¸ªæµé‡éœ€æ±‚è®¡ç®—å¤šè·¯å¾„ (Algorithm 1, Steps 12-30 çš„æ ¸å¿ƒé€»è¾‘)

        è¿‡ç¨‹:
        1. è·å–ç¬¬ä¸€æ¡è·¯å¾„(æœ€çŸ­å»¶è¿Ÿè·¯å¾„)
        2. è¿­ä»£è®¡ç®—K-1æ¡å¤‡ç”¨è·¯å¾„ï¼Œæ¯æ¬¡æ’é™¤ä¹‹å‰è·¯å¾„ä½¿ç”¨çš„é“¾è·¯
        3. ç¡®ä¿æ‰€æœ‰è·¯å¾„éƒ½æ˜¯é“¾è·¯ä¸ç›¸äº¤çš„
        """
        start_time = time.time()
        source, destination = demand.source_id, demand.destination_id
        paths = []

        # ç¬¬ä¸€æ¡è·¯å¾„: æœ€çŸ­å»¶è¿Ÿè·¯å¾„ (Algorithm 1, Step 6-10çš„ç»“æœ)
        node_pair = (source, destination)
        if node_pair in existing_shortest_paths:
            shortest_path = existing_shortest_paths[node_pair]
            paths.append(shortest_path)
        else:
            # å¦‚æœæ²¡æœ‰é¢„è®¡ç®—çš„è·¯å¾„ï¼Œç°åœºè®¡ç®—
            path_finder = DijkstraPathFinder(topology)
            shortest_path = path_finder.find_shortest_path(source, destination, weight_type='delay')
            if shortest_path:
                paths.append(shortest_path)
                self.increment_link_usage(shortest_path)
            else:
                computation_time = time.time() - start_time
                return MultiPathResult(source, destination, [], demand, False, computation_time)

        # è®¡ç®—å¤‡ç”¨è·¯å¾„ (K-1æ¡) (Algorithm 1, Steps 23-30)
        for k in range(1, self.config.K):
            # æ”¶é›†å·²ä½¿ç”¨çš„é“¾è·¯
            excluded_links = set()
            for path in paths:
                for link_tuple in path.links:
                    link_id = tuple(sorted(link_tuple))
                    excluded_links.add(link_id)

            # æŸ¥æ‰¾å¤‡ç”¨è·¯å¾„
            backup_path = self.find_backup_path_with_excluded_links(
                topology, source, destination, excluded_links)

            if backup_path:
                paths.append(backup_path)
                # æ›´æ–°é“¾è·¯ä½¿ç”¨è®¡æ•°
                self.increment_link_usage(backup_path)
            else:
                # æ— æ³•æ‰¾åˆ°æ›´å¤šä¸ç›¸äº¤è·¯å¾„ï¼Œæå‰ç»“æŸ
                break

        computation_time = time.time() - start_time
        return MultiPathResult(source, destination, paths, demand, True, computation_time)

    def run_ldmr_algorithm(self, topology: NetworkTopology,
                           traffic_demands: List[TrafficDemand]) -> List[MultiPathResult]:
        """
        è¿è¡Œå®Œæ•´çš„LDMRç®—æ³• (Algorithm 1 å®Œæ•´å®ç°)

        ä¸»è¦æ­¥éª¤:
        1. åˆå§‹åŒ– (Steps 1-5)
        2. è®¡ç®—æ‰€æœ‰èŠ‚ç‚¹å¯¹çš„æœ€çŸ­å»¶è¿Ÿè·¯å¾„ (Steps 6-10)
        3. æŒ‰æµé‡å¤§å°é™åºå¤„ç†æ¯ä¸ªéœ€æ±‚ (Steps 11-30)
        4. ä¸ºæ¯ä¸ªéœ€æ±‚è®¡ç®—Kæ¡é“¾è·¯ä¸ç›¸äº¤è·¯å¾„
        """
        algorithm_start_time = time.time()

        print(f"ğŸš€ å¼€å§‹è¿è¡ŒLDMRç®—æ³• (Algorithm 1)")
        print(f"     é…ç½®å‚æ•°: K={self.config.K}, Ne_th={self.config.Ne_th}, r3={self.config.r3}")
        print(f"     æµé‡éœ€æ±‚æ•°é‡: {len(traffic_demands)}")

        # Steps 1-5: åˆå§‹åŒ–
        self.reset_algorithm_state()
        results = []

        # åˆå§‹åŒ–æ‹“æ‰‘æƒé‡ä¸ºé“¾è·¯å»¶è¿Ÿ
        for link in topology.links.values():
            link.weight = link.delay

        # Steps 6-10: è®¡ç®—æ‰€æœ‰èŠ‚ç‚¹å¯¹çš„æœ€çŸ­å»¶è¿Ÿè·¯å¾„
        print(f"     Phase 1: è®¡ç®—æœ€çŸ­å»¶è¿Ÿè·¯å¾„...")
        shortest_paths = self.calculate_shortest_delay_paths(topology, traffic_demands)
        print(f"     æ‰¾åˆ° {len(shortest_paths)} æ¡æœ€çŸ­å»¶è¿Ÿè·¯å¾„")

        # Steps 11-30: æŒ‰æµé‡å¤§å°é™åºå¤„ç†æ¯ä¸ªæµé‡éœ€æ±‚
        print(f"     Phase 2: æŒ‰å¸¦å®½é™åºå¤„ç†æµé‡éœ€æ±‚...")
        sorted_demands = sorted(traffic_demands, key=lambda x: x.bandwidth, reverse=True)

        if sorted_demands:
            print(
                f"     å¸¦å®½èŒƒå›´: {sorted_demands[0].bandwidth:.1f}Mbps (æœ€å¤§) - {sorted_demands[-1].bandwidth:.1f}Mbps (æœ€å°)")

        for i, demand in enumerate(sorted_demands):
            print(f"     å¤„ç†éœ€æ±‚ {i + 1}/{len(sorted_demands)}: "
                  f"{demand.source_id}->{demand.destination_id} "
                  f"({demand.bandwidth:.1f}Mbps, ä¼˜å…ˆçº§{demand.priority})")

            # ä¸ºå½“å‰æµé‡éœ€æ±‚è®¡ç®—å¤šè·¯å¾„ (Steps 12-30)
            result = self.calculate_multipath_for_single_demand(topology, demand, shortest_paths)
            results.append(result)

            if result.success:
                print(f"       âœ… æˆåŠŸè®¡ç®— {len(result.paths)} æ¡è·¯å¾„ "
                      f"(æ€»å»¶è¿Ÿ: {result.total_delay:.1f}ms, æ€»è·³æ•°: {result.total_hops})")
            else:
                print(f"       âŒ è·¯å¾„è®¡ç®—å¤±è´¥")

        # è®°å½•æ€»æ‰§è¡Œæ—¶é—´
        total_time = time.time() - algorithm_start_time
        if self.config.enable_statistics:
            self.execution_stats['total_time'] = total_time

        print(f"âœ… LDMRç®—æ³•æ‰§è¡Œå®Œæˆ (è€—æ—¶: {total_time:.2f}ç§’)")
        return results

    def get_algorithm_statistics(self, results: List[MultiPathResult]) -> Dict:
        """è·å–ç®—æ³•æ‰§è¡Œçš„è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯"""
        if not results:
            return {}

        total_demands = len(results)
        successful_results = [r for r in results if r.success]
        successful_demands = len(successful_results)

        # è·¯å¾„ç»Ÿè®¡
        all_paths = []
        for result in successful_results:
            all_paths.extend(result.paths)

        path_lengths = [p.length for p in all_paths]
        path_delays = [p.total_delay for p in all_paths]
        computation_times = [r.computation_time for r in results]

        # åŸºç¡€ç»Ÿè®¡
        stats = {
            'total_demands': total_demands,
            'successful_demands': successful_demands,
            'failed_demands': total_demands - successful_demands,
            'success_rate': successful_demands / total_demands if total_demands > 0 else 0,
            'total_paths_calculated': len(all_paths),
            'avg_paths_per_successful_demand': len(all_paths) / successful_demands if successful_demands > 0 else 0,
        }

        # è·¯å¾„è´¨é‡ç»Ÿè®¡
        if path_lengths:
            stats.update({
                'avg_path_length': np.mean(path_lengths),
                'min_path_length': min(path_lengths),
                'max_path_length': max(path_lengths),
                'std_path_length': np.std(path_lengths),
            })

        if path_delays:
            stats.update({
                'avg_path_delay': np.mean(path_delays),
                'min_path_delay': min(path_delays),
                'max_path_delay': max(path_delays),
                'std_path_delay': np.std(path_delays),
            })

        # æ€§èƒ½ç»Ÿè®¡
        if computation_times:
            stats.update({
                'avg_computation_time': np.mean(computation_times),
                'total_computation_time': sum(computation_times),
                'max_computation_time': max(computation_times),
            })

        # é“¾è·¯ä½¿ç”¨ç»Ÿè®¡
        if self.link_usage_count:
            usage_values = list(self.link_usage_count.values())
            stats.update({
                'total_links_used': len(self.link_usage_count),
                'max_link_usage': max(usage_values),
                'avg_link_usage': np.mean(usage_values),
                'link_usage_distribution': dict(self.link_usage_count),
            })

        # ç®—æ³•æ‰§è¡Œç»Ÿè®¡
        if self.config.enable_statistics:
            stats.update({
                'algorithm_execution_stats': self.execution_stats.copy()
            })

        return stats

    def verify_path_disjointness(self, results: List[MultiPathResult]) -> Dict:
        """éªŒè¯è·¯å¾„çš„é“¾è·¯ä¸ç›¸äº¤æ€§"""
        verification_stats = {
            'total_results_checked': len(results),
            'disjoint_results': 0,
            'non_disjoint_results': 0,
            'disjoint_rate': 0.0,
            'conflicts': []
        }

        for result in results:
            if not result.success or len(result.paths) < 2:
                continue

            # æ£€æŸ¥è¯¥ç»“æœä¸­çš„è·¯å¾„æ˜¯å¦é“¾è·¯ä¸ç›¸äº¤
            all_links = set()
            is_disjoint = True
            conflicts = []

            for i, path in enumerate(result.paths):
                for link_tuple in path.links:
                    link_id = tuple(sorted(link_tuple))
                    if link_id in all_links:
                        is_disjoint = False
                        conflicts.append(f"è·¯å¾„{i + 1}ä¸­çš„é“¾è·¯{link_id}ä¸ä¹‹å‰è·¯å¾„å†²çª")
                    all_links.add(link_id)

            if is_disjoint:
                verification_stats['disjoint_results'] += 1
            else:
                verification_stats['non_disjoint_results'] += 1
                verification_stats['conflicts'].extend(conflicts)

        total_checked = verification_stats['disjoint_results'] + verification_stats['non_disjoint_results']
        if total_checked > 0:
            verification_stats['disjoint_rate'] = verification_stats['disjoint_results'] / total_checked

        return verification_stats


def create_ldmr_config_for_scenario(scenario: str) -> LDMRConfig:
    """ä¸ºä¸åŒåœºæ™¯åˆ›å»ºLDMRé…ç½®"""
    configs = {
        'testing': LDMRConfig(K=2, r1=1, r2=5, r3=20, Ne_th=1),
        'light_load': LDMRConfig(K=2, r1=1, r2=10, r3=30, Ne_th=2),
        'heavy_load': LDMRConfig(K=2, r1=1, r2=10, r3=50, Ne_th=3),
        'high_reliability': LDMRConfig(K=3, r1=1, r2=15, r3=60, Ne_th=2),
        'performance': LDMRConfig(K=2, r1=1, r2=10, r3=50, Ne_th=2, enable_statistics=True)
    }

    return configs.get(scenario, LDMRConfig())


def run_ldmr_simulation(topology: NetworkTopology,
                        traffic_demands: List[TrafficDemand],
                        config: LDMRConfig = None,
                        scenario: str = 'performance') -> Tuple[List[MultiPathResult], Dict]:
    """
    è¿è¡ŒLDMRä»¿çœŸçš„ä¾¿æ·å‡½æ•°

    Args:
        topology: ç½‘ç»œæ‹“æ‰‘
        traffic_demands: æµé‡éœ€æ±‚åˆ—è¡¨
        config: LDMRé…ç½® (å¯é€‰)
        scenario: é¢„å®šä¹‰åœºæ™¯ (å¯é€‰)

    Returns:
        Tuple[List[MultiPathResult], Dict]: (è·¯å¾„è®¡ç®—ç»“æœ, ç»Ÿè®¡ä¿¡æ¯)
    """
    if config is None:
        config = create_ldmr_config_for_scenario(scenario)

    ldmr = LDMRAlgorithm(config)
    results = ldmr.run_ldmr_algorithm(topology, traffic_demands)
    statistics = ldmr.get_algorithm_statistics(results)

    return results, statistics