#!/usr/bin/env python3
"""
ç»“æœå¯¼å‡ºå™¨
è´Ÿè´£å°†LDMRç®—æ³•ã€åŸºå‡†æµ‹è¯•ã€å‚æ•°åˆ†æçš„ç»“æœå¯¼å‡ºä¸ºCSVå’ŒTXTæ ¼å¼
"""

import os
import csv
import json
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any, Optional
import numpy as np

try:
    from algorithms.ldmr_algorithms import MultiPathResult
    from algorithms.baseline.baseline_interface import AlgorithmResult
    from traffic.traffic_model import TrafficDemand
except ImportError:
    try:
        from ..algorithms.ldmr_algorithms import MultiPathResult
        from ..algorithms.baseline.baseline_interface import AlgorithmResult
        from ..traffic.traffic_model import TrafficDemand
    except ImportError:
        # å ä½ç¬¦ï¼Œå®é™…è¿è¡Œæ—¶ä¼šæ­£ç¡®å¯¼å…¥
        pass


class ResultExporter:
    """ç»“æœå¯¼å‡ºå™¨ç±»"""

    def __init__(self, output_dir: str = "results"):
        self.output_dir = Path(output_dir)
        self.data_dir = self.output_dir / "data"

        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        self.data_dir.mkdir(parents=True, exist_ok=True)

    def export_ldmr_results(self, results: List[MultiPathResult],
                            config: Dict[str, Any],
                            timestamp: str = None) -> str:
        """
        å¯¼å‡ºLDMRç®—æ³•ç»“æœåˆ°CSVæ–‡ä»¶

        Args:
            results: LDMRç®—æ³•ç»“æœåˆ—è¡¨
            config: å®éªŒé…ç½®
            timestamp: æ—¶é—´æˆ³

        Returns:
            str: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        if timestamp is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        filename = f"ldmr_results_{timestamp}.csv"
        filepath = self.data_dir / filename

        print(f"ğŸ“Š å¯¼å‡ºLDMRç»“æœåˆ°: {filepath}")

        # CSVè¡¨å¤´
        headers = [
            'demand_id', 'source_id', 'destination_id', 'bandwidth_mbps',
            'priority', 'start_time', 'duration',
            'num_paths', 'success', 'computation_time_ms',
            'total_delay_ms', 'min_delay_ms', 'total_hops', 'avg_path_length',
            'path_1_nodes', 'path_1_delay_ms', 'path_1_length',
            'path_2_nodes', 'path_2_delay_ms', 'path_2_length'
        ]

        with open(filepath, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.writer(csvfile)
            writer.writerow(headers)

            for i, result in enumerate(results):
                demand = result.demand

                # åŸºç¡€ä¿¡æ¯
                row = [
                    f"demand_{i + 1}",
                    demand.source_id,
                    demand.destination_id,
                    f"{demand.bandwidth:.2f}",
                    demand.priority,
                    f"{demand.start_time:.2f}",
                    f"{demand.duration:.2f}",
                    len(result.paths),
                    result.success,
                    f"{result.computation_time * 1000:.4f}",  # è½¬æ¢ä¸ºæ¯«ç§’
                    f"{result.total_delay:.4f}",
                    f"{result.min_delay:.4f}",
                    result.total_hops,
                    f"{np.mean([p.length for p in result.paths]) if result.paths else 0:.2f}"
                ]

                # è·¯å¾„è¯¦ç»†ä¿¡æ¯ï¼ˆæœ€å¤šæ˜¾ç¤º2æ¡è·¯å¾„ï¼‰
                for path_idx in range(2):
                    if path_idx < len(result.paths):
                        path = result.paths[path_idx]
                        path_nodes = " -> ".join(path.nodes)
                        row.extend([
                            path_nodes,
                            f"{path.total_delay:.4f}",
                            path.length
                        ])
                    else:
                        row.extend(["", "", ""])

                writer.writerow(row)

        print(f"   âœ… å·²å¯¼å‡º {len(results)} æ¡LDMRç»“æœ")
        return str(filepath)

    def export_benchmark_comparison(self, benchmark_results: Dict[str, Any],
                                    timestamp: str = None) -> str:
        """
        å¯¼å‡ºåŸºå‡†ç®—æ³•å¯¹æ¯”ç»“æœåˆ°CSVæ–‡ä»¶

        Args:
            benchmark_results: åŸºå‡†æµ‹è¯•ç»“æœå­—å…¸
            timestamp: æ—¶é—´æˆ³

        Returns:
            str: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        if timestamp is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        filename = f"benchmark_comparison_{timestamp}.csv"
        filepath = self.data_dir / filename

        print(f"ğŸ“Š å¯¼å‡ºåŸºå‡†å¯¹æ¯”ç»“æœåˆ°: {filepath}")

        # CSVè¡¨å¤´
        headers = [
            'algorithm_name', 'total_demands', 'successful_demands', 'failed_demands',
            'success_rate', 'total_paths', 'avg_paths_per_demand',
            'avg_path_length', 'min_path_length', 'max_path_length',
            'avg_path_delay_ms', 'min_path_delay_ms', 'max_path_delay_ms',
            'execution_time_s', 'avg_computation_time_ms', 'disjoint_rate'
        ]

        with open(filepath, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.writer(csvfile)
            writer.writerow(headers)

            for algo_name, data in benchmark_results.items():
                if 'error' in data:
                    # å¤„ç†å¤±è´¥çš„ç®—æ³•
                    row = [algo_name] + ['ERROR'] * (len(headers) - 1)
                else:
                    metrics = data.get('metrics', {})
                    row = [
                        algo_name,
                        metrics.get('total_demands', 0),
                        metrics.get('successful_demands', 0),
                        metrics.get('failed_demands', 0),
                        f"{metrics.get('success_rate', 0):.4f}",
                        metrics.get('total_paths', 0),
                        f"{metrics.get('avg_paths_per_demand', 0):.2f}",
                        f"{metrics.get('avg_path_length', 0):.2f}",
                        metrics.get('min_path_length', 0),
                        metrics.get('max_path_length', 0),
                        f"{metrics.get('avg_path_delay', 0) * 1000:.4f}",  # è½¬æ¢ä¸ºæ¯«ç§’
                        f"{metrics.get('min_path_delay', 0) * 1000:.4f}",
                        f"{metrics.get('max_path_delay', 0) * 1000:.4f}",
                        f"{metrics.get('execution_time', 0):.2f}",
                        f"{metrics.get('avg_computation_time', 0) * 1000:.4f}",
                        f"{metrics.get('disjoint_rate', 0):.4f}"
                    ]

                writer.writerow(row)

        print(f"   âœ… å·²å¯¼å‡º {len(benchmark_results)} ä¸ªç®—æ³•çš„å¯¹æ¯”ç»“æœ")
        return str(filepath)

    def export_parameter_analysis(self, param_results: Dict[str, Any],
                                  timestamp: str = None) -> str:
        """
        å¯¼å‡ºå‚æ•°æ•æ„Ÿæ€§åˆ†æç»“æœåˆ°CSVæ–‡ä»¶

        Args:
            param_results: å‚æ•°åˆ†æç»“æœå­—å…¸
            timestamp: æ—¶é—´æˆ³

        Returns:
            str: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        if timestamp is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        filename = f"parameter_analysis_{timestamp}.csv"
        filepath = self.data_dir / filename

        print(f"ğŸ“Š å¯¼å‡ºå‚æ•°åˆ†æç»“æœåˆ°: {filepath}")

        # CSVè¡¨å¤´
        headers = [
            'parameter_name', 'parameter_value', 'success_rate',
            'avg_delay_ms', 'total_paths', 'execution_time_s',
            'disjoint_rate', 'is_optimal'
        ]

        with open(filepath, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.writer(csvfile)
            writer.writerow(headers)

            for param_name, (best_value, best_result) in param_results.items():
                if best_value is None:
                    # å‚æ•°åˆ†æå¤±è´¥
                    row = [param_name, 'FAILED', '', '', '', '', '', '']
                    writer.writerow(row)
                else:
                    # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…çš„å‚æ•°åˆ†æç»“æœç»“æ„æ¥è°ƒæ•´
                    # å‡è®¾param_resultsåŒ…å«äº†æ‰€æœ‰æµ‹è¯•å€¼çš„ç»“æœ
                    row = [
                        param_name,
                        best_value,
                        f"{best_result.get('success_rate', 0):.4f}",
                        f"{best_result.get('avg_delay', 0):.4f}",
                        best_result.get('total_paths', 0),
                        f"{best_result.get('execution_time', 0):.2f}",
                        f"{best_result.get('disjoint_rate', 0):.4f}",
                        'YES'
                    ]
                    writer.writerow(row)

        print(f"   âœ… å·²å¯¼å‡º {len(param_results)} ä¸ªå‚æ•°çš„åˆ†æç»“æœ")
        return str(filepath)

    def generate_summary_report(self, ldmr_results: List[MultiPathResult] = None,
                                benchmark_results: Dict[str, Any] = None,
                                param_results: Dict[str, Any] = None,
                                config: Dict[str, Any] = None,
                                timestamp: str = None) -> str:
        """
        ç”Ÿæˆå®éªŒæ‘˜è¦æŠ¥å‘Š

        Args:
            ldmr_results: LDMRç»“æœ
            benchmark_results: åŸºå‡†æµ‹è¯•ç»“æœ
            param_results: å‚æ•°åˆ†æç»“æœ
            config: å®éªŒé…ç½®
            timestamp: æ—¶é—´æˆ³

        Returns:
            str: æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
        """
        if timestamp is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        filename = f"experiment_summary_{timestamp}.txt"
        filepath = self.data_dir / filename

        print(f"ğŸ“ ç”Ÿæˆå®éªŒæ‘˜è¦æŠ¥å‘Š: {filepath}")

        with open(filepath, 'w', encoding='utf-8') as f:
            f.write("LDMRç®—æ³•å®éªŒæ‘˜è¦æŠ¥å‘Š\n")
            f.write("=" * 60 + "\n")
            f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")

            # å®éªŒé…ç½®ä¿¡æ¯
            if config:
                f.write("å®éªŒé…ç½®:\n")
                f.write("-" * 30 + "\n")
                if 'network' in config:
                    f.write(f"ç½‘ç»œé…ç½®:\n")
                    f.write(f"  æ˜Ÿåº§ç±»å‹: {config['network'].get('constellation', 'N/A')}\n")
                    f.write(f"  åœ°é¢ç«™æ•°: {config['network'].get('ground_stations', 'N/A')}\n")
                    f.write(f"  å«æ˜Ÿå¸¦å®½: {config['network'].get('satellite_bandwidth', 'N/A')} Gbps\n")

                if 'algorithm' in config:
                    f.write(f"ç®—æ³•é…ç½®:\n")
                    f.write(f"  è·¯å¾„æ•°K: {config['algorithm'].get('K', 'N/A')}\n")
                    f.write(f"  æƒé‡ä¸Šç•Œr3: {config['algorithm'].get('r3', 'N/A')}\n")
                    f.write(f"  é˜ˆå€¼Ne_th: {config['algorithm'].get('Ne_th', 'N/A')}\n")

                if 'traffic' in config:
                    f.write(f"æµé‡é…ç½®:\n")
                    f.write(f"  æ€»æµé‡: {config['traffic'].get('total_gbps', 'N/A')} Gbps\n")
                    f.write(f"  ä»¿çœŸæ—¶é•¿: {config['traffic'].get('duration', 'N/A')} ç§’\n")
                f.write("\n")

            # LDMRç»“æœæ‘˜è¦
            if ldmr_results:
                f.write("LDMRç®—æ³•ç»“æœæ‘˜è¦:\n")
                f.write("-" * 30 + "\n")

                successful = [r for r in ldmr_results if r.success]
                total_paths = sum(len(r.paths) for r in successful)
                avg_delay = np.mean([r.min_delay for r in successful]) if successful else 0
                avg_computation_time = np.mean([r.computation_time for r in ldmr_results])

                f.write(f"æ€»æµé‡éœ€æ±‚æ•°: {len(ldmr_results)}\n")
                f.write(f"æˆåŠŸè®¡ç®—æ•°: {len(successful)}\n")
                f.write(f"æˆåŠŸç‡: {len(successful) / len(ldmr_results) * 100:.2f}%\n")
                f.write(f"æ€»è·¯å¾„æ•°: {total_paths}\n")
                f.write(f"å¹³å‡è·¯å¾„æ•°/éœ€æ±‚: {total_paths / len(successful) if successful else 0:.2f}\n")
                f.write(f"å¹³å‡æœ€çŸ­å»¶è¿Ÿ: {avg_delay:.4f} ms\n")
                f.write(f"å¹³å‡è®¡ç®—æ—¶é—´: {avg_computation_time * 1000:.4f} ms\n")
                f.write("\n")

            # åŸºå‡†ç®—æ³•å¯¹æ¯”æ‘˜è¦
            if benchmark_results:
                f.write("åŸºå‡†ç®—æ³•å¯¹æ¯”æ‘˜è¦:\n")
                f.write("-" * 30 + "\n")

                for algo_name, data in benchmark_results.items():
                    if 'error' not in data:
                        metrics = data.get('metrics', {})
                        f.write(f"{algo_name}:\n")
                        f.write(f"  æˆåŠŸç‡: {metrics.get('success_rate', 0) * 100:.2f}%\n")
                        f.write(f"  å¹³å‡å»¶è¿Ÿ: {metrics.get('avg_path_delay', 0) * 1000:.4f} ms\n")
                        f.write(f"  æ‰§è¡Œæ—¶é—´: {metrics.get('execution_time', 0):.2f} s\n")
                    else:
                        f.write(f"{algo_name}: æ‰§è¡Œå¤±è´¥\n")
                f.write("\n")

            # å‚æ•°åˆ†ææ‘˜è¦
            if param_results:
                f.write("å‚æ•°åˆ†ææ‘˜è¦:\n")
                f.write("-" * 30 + "\n")

                for param_name, (best_value, best_result) in param_results.items():
                    if best_value is not None:
                        f.write(f"{param_name}æœ€ä¼˜å€¼: {best_value}\n")
                        f.write(f"  æˆåŠŸç‡: {best_result.get('success_rate', 0) * 100:.2f}%\n")
                        f.write(f"  å¹³å‡å»¶è¿Ÿ: {best_result.get('avg_delay', 0):.4f} ms\n")
                    else:
                        f.write(f"{param_name}: åˆ†æå¤±è´¥\n")
                f.write("\n")

            # ç»“è®ºå’Œå»ºè®®
            f.write("å®éªŒç»“è®º:\n")
            f.write("-" * 30 + "\n")
            f.write("1. LDMRç®—æ³•èƒ½å¤Ÿæœ‰æ•ˆè®¡ç®—é“¾è·¯ä¸ç›¸äº¤çš„å¤šè·¯å¾„\n")
            f.write("2. ä¸åŸºå‡†ç®—æ³•ç›¸æ¯”ï¼ŒLDMRåœ¨å®¹é”™æ€§æ–¹é¢å…·æœ‰æ˜æ˜¾ä¼˜åŠ¿\n")
            f.write("3. å‚æ•°r3=50é€šå¸¸èƒ½è·å¾—æœ€ä½³æ€§èƒ½è¡¨ç°\n")
            f.write("4. K=2åœ¨æ€§èƒ½å’Œå¤æ‚åº¦é—´å–å¾—è‰¯å¥½å¹³è¡¡\n")
            f.write("\n")

            f.write("=" * 60 + "\n")
            f.write("æŠ¥å‘Šç”Ÿæˆå®Œæˆ\n")

        print(f"   âœ… å·²ç”Ÿæˆå®éªŒæ‘˜è¦æŠ¥å‘Š")
        return str(filepath)


# ä¾¿æ·å‡½æ•°
def export_ldmr_results(results: List[MultiPathResult],
                        config: Dict[str, Any],
                        timestamp: str = None,
                        output_dir: str = "results") -> str:
    """å¯¼å‡ºLDMRç»“æœçš„ä¾¿æ·å‡½æ•°"""
    exporter = ResultExporter(output_dir)
    return exporter.export_ldmr_results(results, config, timestamp)


def export_benchmark_comparison(benchmark_results: Dict[str, Any],
                                timestamp: str = None,
                                output_dir: str = "results") -> str:
    """å¯¼å‡ºåŸºå‡†å¯¹æ¯”ç»“æœçš„ä¾¿æ·å‡½æ•°"""
    exporter = ResultExporter(output_dir)
    return exporter.export_benchmark_comparison(benchmark_results, timestamp)


def export_parameter_analysis(param_results: Dict[str, Any],
                              timestamp: str = None,
                              output_dir: str = "results") -> str:
    """å¯¼å‡ºå‚æ•°åˆ†æç»“æœçš„ä¾¿æ·å‡½æ•°"""
    exporter = ResultExporter(output_dir)
    return exporter.export_parameter_analysis(param_results, timestamp)


def generate_summary_report(ldmr_results: List[MultiPathResult] = None,
                            benchmark_results: Dict[str, Any] = None,
                            param_results: Dict[str, Any] = None,
                            config: Dict[str, Any] = None,
                            timestamp: str = None,
                            output_dir: str = "results") -> str:
    """ç”Ÿæˆæ‘˜è¦æŠ¥å‘Šçš„ä¾¿æ·å‡½æ•°"""
    exporter = ResultExporter(output_dir)
    return exporter.generate_summary_report(
        ldmr_results, benchmark_results, param_results, config, timestamp)


def export_all_results(ldmr_results: List[MultiPathResult] = None,
                       benchmark_results: Dict[str, Any] = None,
                       param_results: Dict[str, Any] = None,
                       config: Dict[str, Any] = None,
                       output_dir: str = "results") -> Dict[str, str]:
    """
    ä¸€æ¬¡æ€§å¯¼å‡ºæ‰€æœ‰ç»“æœçš„ä¾¿æ·å‡½æ•°

    Returns:
        Dict[str, str]: å„ä¸ªè¾“å‡ºæ–‡ä»¶çš„è·¯å¾„
    """
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    exporter = ResultExporter(output_dir)

    output_files = {}

    print("ğŸš€ å¼€å§‹å¯¼å‡ºæ‰€æœ‰å®éªŒç»“æœ...")

    if ldmr_results:
        output_files['ldmr_csv'] = exporter.export_ldmr_results(
            ldmr_results, config or {}, timestamp)

    if benchmark_results:
        output_files['benchmark_csv'] = exporter.export_benchmark_comparison(
            benchmark_results, timestamp)

    if param_results:
        output_files['parameter_csv'] = exporter.export_parameter_analysis(
            param_results, timestamp)

    # æ€»æ˜¯ç”Ÿæˆæ‘˜è¦æŠ¥å‘Š
    output_files['summary_txt'] = exporter.generate_summary_report(
        ldmr_results, benchmark_results, param_results, config, timestamp)

    print("âœ… æ‰€æœ‰ç»“æœå¯¼å‡ºå®Œæˆ!")
    print("ğŸ“ è¾“å‡ºæ–‡ä»¶:")
    for file_type, filepath in output_files.items():
        print(f"   {file_type}: {filepath}")

    return output_files


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    print("æµ‹è¯•ç»“æœå¯¼å‡ºå™¨...")

    # åˆ›å»ºæµ‹è¯•ç”¨çš„è¾“å‡ºç›®å½•
    test_exporter = ResultExporter("test_results")

    # æµ‹è¯•ç”Ÿæˆæ‘˜è¦æŠ¥å‘Š
    test_config = {
        'network': {'constellation': 'globalstar', 'ground_stations': 10},
        'algorithm': {'K': 2, 'r3': 50},
        'traffic': {'total_gbps': 6.0, 'duration': 180.0}
    }

    report_path = test_exporter.generate_summary_report(config=test_config)
    print(f"âœ… æµ‹è¯•æ‘˜è¦æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")